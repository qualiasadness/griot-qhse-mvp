import streamlit as st
import google.generativeai as genai
import edge_tts
import asyncio
import nest_asyncio
import tempfile
import os

# Patch pour l'audio sur le Cloud
nest_asyncio.apply()

# ============================================================================
# 1. CONFIGURATION
# ============================================================================

st.set_page_config(
    page_title="Griot QHSE",
    page_icon="üë∑üèø‚Äç‚ôÇÔ∏è",
    layout="centered"
)

st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stApp { background-color: white; }
    
    /* Style statut */
    div[data-testid="stStatusWidget"] {
        border: 1px solid #ddd;
        border-radius: 10px;
        background-color: #f9f9f9;
    }
    
    /* Header simple */
    .header {
        text-align: center;
        padding-bottom: 20px;
        border-bottom: 1px solid #eee;
        margin-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# 2. FONCTIONS TECHNIQUES (MOD√àLE & AUDIO)
# ============================================================================

def trouver_bon_modele(api_key):
    """
    FORCE l'utilisation de FLASH (Gratuit & Rapide).
    √âvite les mod√®les 'Pro' ou 'Exp' qui causent l'erreur 429.
    """
    genai.configure(api_key=api_key)
    try:
        # Liste de pr√©f√©rence (du plus stable au plus r√©cent)
        # On ne veut QUE du flash pour √©viter les limites
        modeles_gratuits = [
            "gemini-1.5-flash",
            "gemini-1.5-flash-001",
            "gemini-1.5-flash-002",
            "gemini-1.5-flash-8b"
        ]
        
        # On demande √† Google ce qui est dispo
        dispo = [m.name.replace("models/", "") for m in genai.list_models()]
        
        # On prend le premier mod√®le gratuit qui existe dans la liste dispo
        for m in modeles_gratuits:
            if m in dispo:
                return f"models/{m}"
        
        # Si on ne trouve rien, on force le standard
        return "models/gemini-1.5-flash"
        
    except Exception:
        # En cas de doute, on renvoie le mod√®le le plus standard
        return "models/gemini-1.5-flash"

async def generer_audio_hd_async(texte, langue):
    """
    G√©n√®re l'audio.
    Si Wolof (wo) -> Utilise la voix Fran√ßaise pour lire (lecture phon√©tique).
    """
    # S√©lection de la voix
    if langue == "en":
        voice = "en-US-ChristopherNeural"
    else:
        # Pour FR et WOLOF, on utilise Henri (Fran√ßais)
        # C'est la seule fa√ßon d'avoir du son pour le Wolof gratuitement
        voice = "fr-FR-HenriNeural"
    
    communicate = edge_tts.Communicate(texte, voice)
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    await communicate.save(tfile.name)
    return tfile.name

def generer_audio(texte, langue):
    try:
        return asyncio.run(generer_audio_hd_async(texte, langue))
    except Exception:
        return None

def detecter_et_repondre(entree, type_entree, api_key, nom_modele):
    genai.configure(api_key=api_key)
    
    # Prompt optimis√© pour la s√©curit√© et la langue
    system_instruction = """
    Tu es le Griot QHSE, expert s√©curit√© S√©n√©gal.
    
    R√àGLES DE R√âPONSE :
    1. Si l'utilisateur parle WOLOF -> R√©ponds en WOLOF. Ajoute [WO] au d√©but.
    2. Si l'utilisateur parle FRAN√áAIS -> R√©ponds en FRAN√áAIS. Ajoute [FR] au d√©but.
    3. Si l'utilisateur parle ANGLAIS -> R√©ponds en ANGLAIS. Ajoute [EN] au d√©but.
    
    Format : Sois bienveillant, clair et cite les normes de s√©curit√© si n√©cessaire.
    """
    
    model = genai.GenerativeModel(nom_modele, system_instruction=system_instruction)
    
    if type_entree == "audio":
        myfile = genai.upload_file(entree)
        response = model.generate_content(["R√©ponds dans la langue parl√©e.", myfile])
        return response.text
    else:
        response = model.generate_content(entree)
        return response.text

# ============================================================================
# 3. INTERFACE UTILISATEUR
# ============================================================================

def main():
    # En-t√™te propre
    st.markdown("""
        <div class="header">
            <h1>üë∑üèø‚Äç‚ôÇÔ∏è Griot QHSE</h1>
            <span style="color:gray">Expert S√©curit√© ‚Ä¢ Wolof / Fran√ßais / English</span>
        </div>
    """, unsafe_allow_html=True)

    # --- SIDEBAR ---
    with st.sidebar:
        st.header("üîë Connexion")
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("Licence Active")
        else:
            api_key = st.text_input("Cl√© API Gemini", type="password")
            
        st.markdown("---")
        if st.button("üóëÔ∏è Effacer la conversation"):
            st.session_state.messages = []
            st.rerun()

    if not api_key:
        st.info("‚¨ÖÔ∏è Entrez votre cl√© API √† gauche pour commencer.")
        return

    # --- S√âLECTION DU MOD√àLE (Une seule fois) ---
    if "modele_actif" not in st.session_state:
        with st.spinner("Configuration du Griot..."):
            st.session_state.modele_actif = trouver_bon_modele(api_key)
            # st.toast(f"Connect√© sur : {st.session_state.modele_actif}") # Debug

    # --- HISTORIQUE ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "audio" in msg:
                st.audio(msg["audio"])

    # --- ZONE D'ENTR√âE ---
    
    # 1. Texte
    prompt_texte = st.chat_input("√âcrivez votre message...")
    
    # 2. Audio (Natif Streamlit)
    prompt_audio = st.audio_input("Ou enregistrez un vocal")

    # LOGIQUE DE CHOIX
    prompt_final = None
    type_input = None
    audio_path_temp = None

    if prompt_audio:
        if "last_audio_processed" not in st.session_state or st.session_state.last_audio_processed != prompt_audio:
            st.session_state.last_audio_processed = prompt_audio
            # Sauvegarde temp
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                f.write(prompt_audio.getvalue())
                audio_path_temp = f.name
            
            prompt_final = audio_path_temp
            type_input = "audio"
            
    elif prompt_texte:
        prompt_final = prompt_texte
        type_input = "texte"

    # --- TRAITEMENT ---
    if prompt_final:
        # Affichage User
        with st.chat_message("user"):
            if type_input == "audio":
                st.markdown("üé§ *Message vocal envoy√©...*")
            else:
                st.markdown(prompt_final)
        
        # Sauvegarde User
        st.session_state.messages.append({
            "role": "user", 
            "content": prompt_final if type_input == "texte" else "üé§ *Vocal*"
        })

        # R√©ponse Assistant
        with st.chat_message("assistant"):
            status = st.status("Traitement en cours...", expanded=True)
            
            try:
                # 1. Texte
                status.write("üß† R√©flexion...")
                reponse = detecter_et_repondre(
                    prompt_final, 
                    type_input, 
                    api_key, 
                    st.session_state.modele_actif
                )
                
                # 2. Nettoyage
                lang = "fr"
                texte_propre = reponse
                
                if "[WO]" in reponse:
                    lang = "wo"
                    texte_propre = reponse.replace("[WO]", "")
                elif "[EN]" in reponse:
                    lang = "en"
                    texte_propre = reponse.replace("[EN]", "")
                elif "[FR]" in reponse:
                    lang = "fr"
                    texte_propre = reponse.replace("[FR]", "")
                
                # 3. Audio
                status.write("üó£Ô∏è Synth√®se vocale...")
                audio_sortie = generer_audio(texte_propre, lang)
                
                status.update(label="R√©ponse pr√™te !", state="complete", expanded=False)
                
                # Affichage
                st.markdown(texte_propre)
                if audio_sortie:
                    st.audio(audio_sortie)
                    if lang == "wo":
                        st.caption("‚ÑπÔ∏è *Lecture phon√©tique (Wolof)*")
                
                # Sauvegarde Bot
                msg_data = {"role": "assistant", "content": texte_propre}
                if audio_sortie:
                    msg_data["audio"] = audio_sortie
                st.session_state.messages.append(msg_data)
                
                # M√©nage
                if audio_path_temp: os.unlink(audio_path_temp)

            except Exception as e:
                status.update(label="Erreur", state="error")
                if "429" in str(e):
                    st.error("‚ö†Ô∏è Trop de demandes rapides. Attendez 1 minute.")
                else:
                    st.error(f"Erreur : {str(e)}")

if __name__ == "__main__":
    main()
