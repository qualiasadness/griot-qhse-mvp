import streamlit as st
import google.generativeai as genai
import sqlite3
from datetime import datetime
import edge_tts
import asyncio
import nest_asyncio
from streamlit_mic_recorder import mic_recorder
import tempfile
import os

# Application du patch pour asyncio dans Streamlit
nest_asyncio.apply()

# ============================================================================
# 1. CONFIGURATION ET DESIGN PRO (CSS AVANC√â)
# ============================================================================

st.set_page_config(
    page_title="Griot QHSE | Plateforme S√©curit√©",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Palette de couleurs : Bleu Nuit (Confiance), Or (S√©n√©gal), Blanc (Propret√©)
st.markdown("""
<style>
    /* Masquer les √©l√©ments Streamlit par d√©faut pour faire "Logiciel" */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Fond g√©n√©ral */
    .stApp {
        background-color: #F8F9FA;
    }

    /* Barre lat√©rale pro */
    section[data-testid="stSidebar"] {
        background-color: #0F172A; /* Bleu tr√®s fonc√© */
        color: white;
    }
    section[data-testid="stSidebar"] h1, section[data-testid="stSidebar"] h2, section[data-testid="stSidebar"] h3 {
        color: #F1F5F9 !important;
    }
    
    /* Header personnalis√© */
    .custom-header {
        background: white;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        display: flex;
        align-items: center;
        justify-content: space-between;
        margin-bottom: 2rem;
        border-bottom: 4px solid #D97706; /* Or */
    }
    .custom-header h1 {
        margin: 0;
        color: #1E293B;
        font-family: 'Segoe UI', sans-serif;
        font-size: 1.8rem;
    }
    .custom-header p {
        margin: 0;
        color: #64748B;
    }

    /* Bulles de chat style WhatsApp/Messenger */
    .stChatMessage {
        background-color: transparent;
        border: none;
    }
    div[data-testid="stChatMessageContent"] {
        padding: 15px;
        border-radius: 15px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
        font-family: 'Helvetica', sans-serif;
        line-height: 1.6;
    }
    /* Bulle Assistant (Griot) */
    div[data-testid="chatAvatarIcon-assistant"] + div[data-testid="stChatMessageContent"] {
        background-color: #FFFFFF;
        border-left: 5px solid #D97706;
        color: #334155;
    }
    /* Bulle Utilisateur */
    div[data-testid="chatAvatarIcon-user"] + div[data-testid="stChatMessageContent"] {
        background-color: #DBEAFE; /* Bleu clair */
        color: #1E3A8A;
        text-align: right;
    }

    /* Boutons stylis√©s */
    .stButton button {
        background-color: #D97706;
        color: white;
        border-radius: 8px;
        border: none;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
    .stButton button:hover {
        background-color: #B45309;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# 2. FONCTIONS SYST√àME (DB & AUDIO HD)
# ============================================================================

def init_db():
    try:
        conn = sqlite3.connect('qhse_master.db')
        c = conn.cursor()
        c.execute('''CREATE TABLE IF NOT EXISTS interactions 
                     (id INTEGER PRIMARY KEY, titre TEXT, question TEXT, reponse TEXT, timestamp DATETIME)''')
        conn.commit()
        conn.close()
    except: pass

def get_history():
    try:
        conn = sqlite3.connect('qhse_master.db')
        c = conn.cursor()
        c.execute("SELECT id, titre, timestamp FROM interactions ORDER BY id DESC LIMIT 10")
        data = c.fetchall()
        conn.close()
        return data
    except: return []

def save_interaction(question, reponse):
    try:
        # On g√©n√®re un titre court pour l'historique (les 30 premiers caract√®res)
        titre = (question[:25] + '...') if len(question) > 25 else question
        conn = sqlite3.connect('qhse_master.db')
        c = conn.cursor()
        c.execute("INSERT INTO interactions (titre, question, reponse, timestamp) VALUES (?, ?, ?, ?)",
                  (titre, question, reponse, datetime.now()))
        conn.commit()
        conn.close()
    except: pass

# --- AUDIO HAUTE QUALIT√â (EDGE TTS) ---
async def generer_audio_hd_async(texte, langue):
    """G√©n√®re un audio ultra-r√©aliste avec Microsoft Edge TTS."""
    if langue == "wo": return None # Wolof toujours pas support√© en TTS HD
    
    # Choix de la voix selon la langue
    voice = "fr-FR-HenriNeural" if langue == "fr" else "en-US-ChristopherNeural"
    
    communicate = edge_tts.Communicate(texte[:800], voice) # Limite pour la rapidit√©
    
    # Fichier temp
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    await communicate.save(tfile.name)
    return tfile.name

def generer_audio_hd(texte, langue):
    """Wrapper pour appeler la fonction async."""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # Si une boucle tourne d√©j√† (Streamlit), on utilise run_until_complete est risqu√©
            # On recr√©e une boucle locale juste pour √ßa ou on utilise asyncio.run si possible
            # Ici, nest_asyncio nous sauve.
            return loop.run_until_complete(generer_audio_hd_async(texte, langue))
        else:
            return asyncio.run(generer_audio_hd_async(texte, langue))
    except Exception as e:
        return None

# ============================================================================
# 3. INTELLIGENCE (TEXTE & AUDIO INPUT)
# ============================================================================

def get_gemini_model(api_key):
    genai.configure(api_key=api_key)
    # Recherche automatique du mod√®le
    for m in ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']:
        try:
            model = genai.GenerativeModel(m)
            # Test l√©ger
            model.generate_content("Test")
            return m
        except: continue
    return "models/gemini-1.5-flash"

def traiter_requete(entree_utilisateur, type_entree, api_key, model_name):
    """
    Traite soit du texte, soit de l'audio (bytes).
    Gemini Flash est MULTIMODAL : Il √©coute l'audio !
    """
    genai.configure(api_key=api_key)
    
    system_instruction = """
    R√¥le : Griot QHSE, expert s√©curit√© S√©n√©gal.
    Contexte : Tu parles √† un travailleur.
    Langues : 
    - Si on parle Wolof -> R√©ponds Wolof Authentique. Tag [WO].
    - Si on parle Fran√ßais -> R√©ponds Fran√ßais Pro. Tag [FR].
    - Si on parle Anglais -> R√©ponds Anglais. Tag [EN].
    Consigne : Sois humain, direct, ne dis pas "je suis une IA".
    """
    
    model = genai.GenerativeModel(model_name, system_instruction=system_instruction)

    try:
        if type_entree == "audio":
            # On envoie l'audio brut √† Gemini !
            # Il faut sauvegarder les bytes dans un fichier temporaire pour l'envoyer
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            tfile.write(entree_utilisateur)
            tfile.close()
            
            # Upload du fichier chez Google (temporaire)
            myfile = genai.upload_file(tfile.name)
            
            # Prompt multimodal
            response = model.generate_content(["√âcoute cet audio. Si c'est du Wolof, r√©ponds en Wolof. Sinon r√©ponds dans la langue d√©tect√©e.", myfile])
            
            # Nettoyage
            os.unlink(tfile.name)
        else:
            # Texte simple
            response = model.generate_content(entree_utilisateur)
            
        return response.text
        
    except Exception as e:
        return f"[FR] Erreur technique : {str(e)}"

# ============================================================================
# 4. INTERFACE UTILISATEUR
# ============================================================================

def main():
    init_db()
    
    # --- SIDEBAR (Menu Logiciel) ---
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Panneau de Contr√¥le")
        
        # Cl√© API
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("Licence Active ‚úÖ")
        else:
            api_key = st.text_input("Cl√© de Licence (API)", type="password")
            
        st.markdown("---")
        
        # Historique Visuel
        st.markdown("### üóÑÔ∏è Dossiers R√©cents")
        historique = get_history()
        if historique:
            for item in historique:
                # Cr√©ation de boutons pour chaque entr√©e d'historique
                if st.button(f"üìÑ {item[1]}", key=item[0], help=item[2]):
                    # Recharger une question n'est pas simple en Streamlit "chat", 
                    # mais on montre qu'on a la donn√©e.
                    st.toast("Chargement du dossier... (Fonctionnalit√© D√©mo)")
        else:
            st.caption("Aucun dossier enregistr√©.")

        st.markdown("---")
        st.markdown("<div style='text-align: center; color: #64748B; font-size: 0.8em;'>v3.0.1 - Ultimate Edition</div>", unsafe_allow_html=True)

    # --- ZONE PRINCIPALE ---
    
    # En-t√™te Custom
    st.markdown("""
    <div class="custom-header">
        <div>
            <h1>ü¶Å Griot QHSE</h1>
            <p>Assistant Intelligent de S√©curit√© au Travail</p>
        </div>
        <div style="background: #ECFDF5; color: #047857; padding: 5px 15px; border-radius: 20px; font-weight: bold; font-size: 0.9em;">
            üü¢ En Ligne
        </div>
    </div>
    """, unsafe_allow_html=True)

    if not api_key:
        st.warning("‚ö†Ô∏è En attente de la cl√© d'activation dans le panneau lat√©ral.")
        return

    # Gestion de l'√©tat (Session)
    if "messages" not in st.session_state:
        st.session_state.messages = [{
            "role": "assistant", 
            "content": "Salamalekum ! üëãüèø\n\nJe suis pr√™t. Vous pouvez m'√©crire ou m'envoyer un message vocal (Wolof, Fran√ßais, Anglais)."
        }]
    
    # D√©tection du mod√®le une seule fois
    if "model_name" not in st.session_state:
        st.session_state.model_name = get_gemini_model(api_key)

    # Affichage Chat
    for msg in st.session_state.messages:
        avatar = "ü¶Å" if msg["role"] == "assistant" else "üë§"
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # --- ZONE D'ENTR√âE (Hybride : Texte + Audio) ---
    
    col_mic, col_text = st.columns([1, 4])
    
    audio_bytes = None
    user_text = None
    
    with col_mic:
        st.markdown("**Vocal**")
        # Enregistreur Audio
        audio_data = mic_recorder(
            start_prompt="üî¥",
            stop_prompt="‚èπÔ∏è",
            key='recorder',
            format="wav",
            use_container_width=True
        )
        if audio_data:
            audio_bytes = audio_data['bytes']

    with col_text:
        user_text = st.chat_input("√âcrivez votre message ici...")

    # LOGIQUE DE TRAITEMENT
    prompt_final = None
    type_input = None
    
    # Priorit√© √† l'audio s'il vient d'√™tre enregistr√©
    if audio_bytes and "last_audio_id" not in st.session_state:
        st.session_state.last_audio_id = audio_data['id'] # Pour √©viter de traiter le m√™me audio 2 fois
        prompt_final = audio_bytes
        type_input = "audio"
        display_msg = "üé§ *Message Vocal envoy√©...*"
    elif audio_bytes and st.session_state.last_audio_id != audio_data['id']:
         st.session_state.last_audio_id = audio_data['id']
         prompt_final = audio_bytes
         type_input = "audio"
         display_msg = "üé§ *Message Vocal envoy√©...*"
    elif user_text:
        prompt_final = user_text
        type_input = "text"
        display_msg = user_text

    if prompt_final:
        # 1. Afficher message User
        st.session_state.messages.append({"role": "user", "content": display_msg})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(display_msg)

        # 2. R√©ponse Assistant
        with st.chat_message("assistant", avatar="ü¶Å"):
            placeholder = st.empty()
            with st.spinner("Analyse en cours..."):
                
                reponse_brute = traiter_requete(
                    prompt_final, 
                    type_input, 
                    api_key, 
                    st.session_state.model_name
                )
                
                # Parsing
                if "[WO]" in reponse_brute:
                    lang, txt = "wo", reponse_brute.replace("[WO]", "")
                elif "[EN]" in reponse_brute:
                    lang, txt = "en", reponse_brute.replace("[EN]", "")
                elif "[FR]" in reponse_brute:
                    lang, txt = "fr", reponse_brute.replace("[FR]", "")
                else:
                    lang, txt = "fr", reponse_brute

                placeholder.markdown(txt)
                
                # Audio HD
                if lang == "wo":
                    st.caption("üîá *Audio non disponible pour le Wolof (limitation technique)*")
                else:
                    audio_path = generer_audio_hd(txt, lang)
                    if audio_path:
                        st.audio(audio_path, format="audio/mp3", start_time=0)
                        # Pas de suppression imm√©diate sinon Streamlit perd le fichier avant lecture
        
        # 3. Sauvegarde
        st.session_state.messages.append({"role": "assistant", "content": txt})
        save_interaction(display_msg if type_input == "text" else "Message Vocal", txt)

if __name__ == "__main__":
    main()
