import streamlit as st
import google.generativeai as genai
import edge_tts
import asyncio
import nest_asyncio
import tempfile
import os

# Patch technique indispensable pour l'audio sur le Cloud
nest_asyncio.apply()

# ============================================================================
# 1. CONFIGURATION
# ============================================================================

st.set_page_config(
    page_title="Griot QHSE",
    page_icon="üë∑üèø‚Äç‚ôÇÔ∏è",
    layout="centered"
)

# Style √©pur√© (Fond blanc, chat propre)
st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stApp { background-color: white; }
    div[data-testid="stStatusWidget"] {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 10px;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# 2. FONCTION ANTI-ERREUR 404 (CRITIQUE)
# ============================================================================

def trouver_modele_disponible(api_key):
    """
    Cette fonction liste les mod√®les r√©ellement disponibles pour TA cl√©.
    Elle √©vite l'erreur 404 en ne prenant qu'un mod√®le qui existe.
    """
    genai.configure(api_key=api_key)
    try:
        # On demande la liste √† Google
        liste_modeles = genai.list_models()
        
        # On cherche un mod√®le 'flash' (gratuit et rapide)
        for m in liste_modeles:
            if 'generateContent' in m.supported_generation_methods:
                if 'flash' in m.name.lower():
                    return m.name  # On retourne le nom exact
        
        # Si pas de flash, on prend le premier 'gemini' dispo
        for m in liste_modeles:
             if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name.lower():
                 return m.name
                 
        return 'gemini-1.5-flash' # Fallback ultime
        
    except Exception as e:
        return 'gemini-1.5-flash'

# ============================================================================
# 3. FONCTIONS AUDIO & IA
# ============================================================================

async def generer_audio_hd_async(texte, langue):
    # Voix Fran√ßaise (Henri) utilis√©e pour FR et WOLOF (lecture phon√©tique)
    # Voix Anglaise (Christopher) pour l'anglais
    voice = "en-US-ChristopherNeural" if langue == "en" else "fr-FR-HenriNeural"
    
    communicate = edge_tts.Communicate(texte, voice)
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    await communicate.save(tfile.name)
    return tfile.name

def generer_audio(texte, langue):
    try:
        return asyncio.run(generer_audio_hd_async(texte, langue))
    except: return None

def repondre_avec_ia(entree, type_entree, api_key, nom_modele):
    genai.configure(api_key=api_key)
    
    system_instruction = """
    Tu es le Griot QHSE, expert s√©curit√© S√©n√©gal.
    1. Si Wolof : R√©ponds en WOLOF. Commence par [WO].
    2. Si Fran√ßais : R√©ponds en FRAN√áAIS. Commence par [FR].
    3. Si Anglais : R√©ponds en ANGLAIS. Commence par [EN].
    Sois bref, paternel et technique (normes ISO, EPI).
    """
    
    # Utilisation du nom de mod√®le D√âCOUVERT (pas devin√©)
    model = genai.GenerativeModel(nom_modele, system_instruction=system_instruction)
    
    if type_entree == "audio":
        myfile = genai.upload_file(entree)
        response = model.generate_content(["R√©ponds dans la langue parl√©e.", myfile])
    else:
        response = model.generate_content(entree)
        
    return response.text

# ============================================================================
# 4. INTERFACE UTILISATEUR
# ============================================================================

def main():
    # En-t√™te simple
    st.markdown("<h1 style='text-align: center;'>üë∑üèø‚Äç‚ôÇÔ∏è Griot QHSE</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: gray;'>Expert S√©curit√© ‚Ä¢ Wolof / Fran√ßais / English</p>", unsafe_allow_html=True)

    # --- GESTION DE LA CL√â API (SECRETS) ---
    api_key = None
    
    if "GEMINI_API_KEY" in st.secrets:
        # Cas 1 : La cl√© est dans les secrets (D√©ploiement Cloud)
        api_key = st.secrets["GEMINI_API_KEY"]
    else:
        # Cas 2 : Pas de secret, on demande √† l'utilisateur (Mode test)
        with st.sidebar:
            st.warning("‚ö†Ô∏è Mode Test")
            api_key = st.text_input("Cl√© API Gemini", type="password")

    if not api_key:
        st.info("Configuration requise : Ajoutez GEMINI_API_KEY dans les secrets pour activer l'app.")
        return

    # --- INITIALISATION INTELLIGENTE ---
    if "modele_nom" not in st.session_state:
        # On cherche le mod√®le UNE SEULE FOIS au d√©marrage
        modele_trouve = trouver_modele_disponible(api_key)
        st.session_state.modele_nom = modele_trouve

    # --- HISTORIQUE ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "audio" in msg:
                st.audio(msg["audio"])

    # --- ENTR√âES ---
    # NOUVEAU MICRO OFFICIEL
    prompt_audio = st.audio_input("Enregistrer un vocal")
    prompt_texte = st.chat_input("√âcrire un message...")

    prompt_final = None
    type_input = None
    temp_path = None

    # Priorit√© Audio > Texte
    if prompt_audio:
        if "last_audio" not in st.session_state or st.session_state.last_audio != prompt_audio:
            st.session_state.last_audio = prompt_audio
            # Sauvegarde temporaire
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                f.write(prompt_audio.getvalue())
                temp_path = f.name
            prompt_final = temp_path
            type_input = "audio"
            
    elif prompt_texte:
        prompt_final = prompt_texte
        type_input = "texte"

    # --- TRAITEMENT ---
    if prompt_final:
        # Affichage User
        with st.chat_message("user"):
            if type_input == "audio":
                st.markdown("üé§ *Vocal envoy√©*")
            else:
                st.markdown(prompt_final)
        
        st.session_state.messages.append({"role": "user", "content": prompt_final if type_input == "texte" else "üé§ *Vocal*"})

        # R√©ponse
        with st.chat_message("assistant"):
            status = st.status("Le Griot r√©fl√©chit...", expanded=True)
            try:
                # 1. Texte
                status.write("üß† Analyse...")
                reponse = repondre_avec_ia(prompt_final, type_input, api_key, st.session_state.modele_nom)
                
                # 2. Parsing Langue
                lang = "fr"
                texte_clean = reponse
                if "[WO]" in reponse:
                    lang = "wo"
                    texte_clean = reponse.replace("[WO]", "")
                elif "[EN]" in reponse:
                    lang = "en"
                    texte_clean = reponse.replace("[EN]", "")
                elif "[FR]" in reponse:
                    lang = "fr"
                    texte_clean = reponse.replace("[FR]", "")

                # 3. Audio Output
                status.write("üó£Ô∏è Synth√®se vocale...")
                audio_out = generer_audio(texte_clean, lang)
                
                status.update(label="Termin√©", state="complete", expanded=False)
                
                st.markdown(texte_clean)
                if audio_out:
                    st.audio(audio_out)
                    if lang == "wo":
                        st.caption("‚ÑπÔ∏è *Lecture phon√©tique (Wolof)*")

                # Save
                msg_data = {"role": "assistant", "content": texte_clean}
                if audio_out: msg_data["audio"] = audio_out
                st.session_state.messages.append(msg_data)
                
                if temp_path:
                    os.unlink(temp_path)

            except Exception as e:
                status.update(label="Erreur", state="error")
                st.error(f"Erreur technique : {e}")

if __name__ == "__main__":
    main()
