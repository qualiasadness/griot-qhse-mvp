import streamlit as st
import google.generativeai as genai
import edge_tts
import asyncio
import nest_asyncio
import tempfile
import os

# Patch pour l'audio sur le Cloud
nest_asyncio.apply()

# ============================================================================
# 1. CONFIGURATION
# ============================================================================

st.set_page_config(
    page_title="Griot QHSE",
    page_icon="üë∑üèø‚Äç‚ôÇÔ∏è",
    layout="centered"
)

st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stApp { background-color: white; }
    /* Style pour le statut */
    div[data-testid="stStatusWidget"] {
        border: 1px solid #ddd;
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# 2. FONCTIONS TECHNIQUES INTELLIGENTES
# ============================================================================

def trouver_vrai_nom_modele(api_key):
    """
    Cette fonction emp√™che l'erreur 404.
    Elle demande √† Google quel nom utiliser exactement.
    """
    genai.configure(api_key=api_key)
    try:
        # On liste les mod√®les disponibles pour TA cl√©
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                # On cherche le flash en priorit√© (gratuit et rapide)
                if 'flash' in m.name:
                    return m.name
                # Sinon le pro
                if 'pro' in m.name:
                    return m.name
        # Si on ne trouve rien de pr√©cis, on renvoie un d√©faut
        return 'models/gemini-1.5-flash'
    except Exception as e:
        # En cas d'erreur de connexion
        return None

async def generer_audio_hd_async(texte, langue):
    """
    G√©n√®re l'audio.
    Si Wolof (wo) -> On utilise la voix Fran√ßaise (Henri) pour lire le texte phon√©tiquement.
    """
    # S√©lection de la voix
    if langue == "en":
        voice = "en-US-ChristopherNeural"
    else:
        # Pour FR et WOLOF, on utilise Henri (Fran√ßais)
        voice = "fr-FR-HenriNeural"
    
    communicate = edge_tts.Communicate(texte, voice)
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    await communicate.save(tfile.name)
    return tfile.name

def generer_audio(texte, langue):
    try:
        return asyncio.run(generer_audio_hd_async(texte, langue))
    except Exception as e:
        return None

def detecter_et_repondre(entree, type_entree, api_key, nom_modele):
    genai.configure(api_key=api_key)
    
    system_instruction = """
    Tu es le Griot QHSE, expert s√©curit√© S√©n√©gal.
    
    R√àGLES IMPORTANTES :
    1. Si l'utilisateur √©crit/parle en WOLOF : R√©ponds en WOLOF. Ajoute le tag [WO] au d√©but.
    2. Si l'utilisateur √©crit/parle en FRAN√áAIS : R√©ponds en FRAN√áAIS. Ajoute le tag [FR] au d√©but.
    3. Si l'utilisateur √©crit/parle en ANGLAIS : R√©ponds en ANGLAIS. Ajoute le tag [EN] au d√©but.
    
    Sois bref et direct.
    """
    
    model = genai.GenerativeModel(nom_modele, system_instruction=system_instruction)
    
    if type_entree == "audio":
        myfile = genai.upload_file(entree)
        response = model.generate_content(["R√©ponds dans la langue de cet audio.", myfile])
        return response.text
    else:
        response = model.generate_content(entree)
        return response.text

# ============================================================================
# 3. INTERFACE
# ============================================================================

def main():
    st.title("üë∑üèø‚Äç‚ôÇÔ∏è Griot QHSE")
    st.caption("Expert S√©curit√© ‚Ä¢ Wolof / Fran√ßais / English")

    # --- SIDEBAR ---
    with st.sidebar:
        st.header("üîë Connexion")
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("Cl√© API Active")
        else:
            api_key = st.text_input("Cl√© API Gemini", type="password")
            
        if st.button("üîÑ Reset"):
            st.session_state.messages = []
            st.rerun()

    if not api_key:
        st.warning("Entrez votre cl√© API √† gauche pour commencer.")
        return

    # --- RECHERCHE DU MOD√àLE (Anti-Erreur 404) ---
    if "nom_modele_valide" not in st.session_state:
        with st.spinner("Connexion √† Google..."):
            nom = trouver_vrai_nom_modele(api_key)
            if nom:
                st.session_state.nom_modele_valide = nom
                # st.toast(f"Connect√© √† : {nom}") # Debug optionnel
            else:
                st.error("Impossible de trouver un mod√®le. V√©rifiez votre Cl√© API.")
                return

    # --- HISTORIQUE ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "audio" in msg:
                st.audio(msg["audio"])

    # --- ENTR√âES (TEXTE OU VOCAL) ---
    prompt_texte = st.chat_input("Votre message (Wolof / Fr)...")
    prompt_audio = st.audio_input("Ou enregistrez un vocal")

    # Logique de s√©lection
    prompt_final = None
    type_input = None
    audio_path_temp = None

    if prompt_audio:
        if "last_audio_id" not in st.session_state or st.session_state.last_audio_id != prompt_audio:
            st.session_state.last_audio_id = prompt_audio
            # Sauvegarde temporaire du fichier audio utilisateur
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                f.write(prompt_audio.getvalue())
                audio_path_temp = f.name
            
            prompt_final = audio_path_temp
            type_input = "audio"
            
    elif prompt_texte:
        prompt_final = prompt_texte
        type_input = "texte"

    # --- TRAITEMENT ---
    if prompt_final:
        # Affiche le message User
        with st.chat_message("user"):
            if type_input == "audio":
                st.markdown("üé§ *Message vocal envoy√©...*")
            else:
                st.markdown(prompt_final)
        
        # Ajout historique User
        st.session_state.messages.append({
            "role": "user", 
            "content": prompt_final if type_input == "texte" else "üé§ *Vocal*"
        })

        # R√©ponse Bot
        with st.chat_message("assistant"):
            status = st.status("Traitement en cours...", expanded=True)
            
            try:
                # 1. G√©n√©ration Texte
                status.write("üß† Le Griot r√©fl√©chit...")
                reponse = detecter_et_repondre(
                    prompt_final, 
                    type_input, 
                    api_key, 
                    st.session_state.nom_modele_valide
                )
                
                # 2. D√©tection Langue
                lang = "fr"
                texte_propre = reponse
                
                if "[WO]" in reponse:
                    lang = "wo" # On garde 'wo' pour savoir, mais l'audio sera forc√©
                    texte_propre = reponse.replace("[WO]", "")
                elif "[EN]" in reponse:
                    lang = "en"
                    texte_propre = reponse.replace("[EN]", "")
                elif "[FR]" in reponse:
                    lang = "fr"
                    texte_propre = reponse.replace("[FR]", "")
                
                status.write("üó£Ô∏è G√©n√©ration de la voix...")
                
                # 3. G√©n√©ration Audio (M√™me pour Wolof maintenant !)
                audio_sortie = generer_audio(texte_propre, lang)
                
                status.update(label="Termin√© !", state="complete", expanded=False)
                
                # Affichage
                st.markdown(texte_propre)
                if audio_sortie:
                    st.audio(audio_sortie)
                    if lang == "wo":
                        st.caption("‚ÑπÔ∏è *Lecture avec accent fran√ßais (le Wolof n'est pas support√© nativement)*")
                
                # Sauvegarde historique Bot
                msg_data = {"role": "assistant", "content": texte_propre}
                if audio_sortie:
                    msg_data["audio"] = audio_sortie
                st.session_state.messages.append(msg_data)
                
                # Nettoyage
                if audio_path_temp: os.unlink(audio_path_temp)

            except Exception as e:
                status.update(label="Erreur", state="error")
                st.error(f"Erreur : {str(e)}")

if __name__ == "__main__":
    main()
